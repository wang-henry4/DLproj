\documentclass{article}
\usepackage{graphicx}
\usepackage{subcaption}
\graphicspath{ {figures/} }
\begin{document}
 
\section{Introduction}
There are now many neural network methods and architectures designed for 
image classification that perform exceptionaly well. These models were trained
on millions of images, with powerful GPU acceleration. However in many cases where
an individual or group needs a model for an image classification task, these pretrained
models do cannot be applied directly. In this case, the usual solution is to use transfer learning.
Using the pretrained model as a feature extractor, we pass our task specific data into a 
pretrained model and then train a linear classifier using the extracted features of our images.
\begin{figure}[h!]
    \includegraphics[scale=0.43]{Examples-in-the-ImageNet-dataset.png}
    \caption{Example images in the ImageNet dataset}
\end{figure}

However, these pretrained models are usually trained on the ImageNet dataset. This dataset is a large
collection of images of real world objects such as animals, like dogs and cats, and other objects like cars.
Thus we would expect these models to be good at extracting features from images that are similar to ImageNet,
aka realworld, everyday objects. If we want to apply these models to images that are very different from 
the ImageNet dataset, such as the Human Protein dataset, we would expect the model to 
not be able to extract very good features.

\subsection{Human Protein Dataset}
\begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{0.2\linewidth}
      \includegraphics[width=\linewidth]{../../data/train/0a2abec8-bbb7-11e8-b2ba-ac1f6b6435d0.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.2\linewidth}
      \includegraphics[width=\linewidth]{../../data/train/0a6068e8-bbb7-11e8-b2ba-ac1f6b6435d0.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{../../data/train/0a74debc-bbc2-11e8-b2bb-ac1f6b6435d0.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{../../data/train/0bac19d6-bbc1-11e8-b2bb-ac1f6b6435d0.png}
    \end{subfigure}

    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{../../data/train/0ea71d6c-bbb1-11e8-b2ba-ac1f6b6435d0.png}
      \end{subfigure}
      \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{../../data/train/1a490006-bbaf-11e8-b2ba-ac1f6b6435d0.png}
      \end{subfigure}
      \begin{subfigure}[b]{0.2\linewidth}
          \includegraphics[width=\linewidth]{../../data/train/1e48964e-bbb4-11e8-b2ba-ac1f6b6435d0.png}
      \end{subfigure}
      \begin{subfigure}[b]{0.2\linewidth}
          \includegraphics[width=\linewidth]{../../data/train/fcb70c22-bbc2-11e8-b2bc-ac1f6b6435d0.png}
      \end{subfigure}
    \caption{Example images from the Human Protein dataset}
  \end{figure}
\subsection{Extracting Features}
It has been shown that in a deep convolutional neural network trained for image classification, the
feature maps of the network start very simple, looking for edges and corners, and become increasingly
complex as the layers get deeper. 

Examining some samples of the Human Protein dataset reveals them to be very different from ImageNet. They 
do not have much of the complex features that any real world image would have, and are mostly made up of 
lines, and circles and corners. Therefore we predict that early layers from a pretrained model will
provide good features for classification for this dataset, while later layers will perform comparatively worse, 
due to the fact that the more complex patterns that the later layers are looking for do not exist in this 
dataset. 

In this paper we test this hypothesis by using a pretrained model as a feature extractor, we choose multiple different
hidden layers to from this model, and train a classifier on each different layer. We find that the best performing classifier
for the Human Protein dataset is the one with the earliest layer hidden layer as its feature extractor.
\section{Method}
We are seaking to test the feature extraction power of pretrained networks on 
a dataset that is very different from the one which it is trained on. We take 
a pretrained, state-of-the-art image classification model, ResNet50V2, and take
the feature maps of the model at different levels to use as the features for 
a linear classifier, which we train on our human protein data. We freeze the weights
of the pretrained model and train only the added layers at the end.
\subsection{Data}
Our data consists of rgb images of human proteins, we process these into 3x224x224 sized
arrays as the input to our model. There are a total of 28 different possible classes,
and each image can belong to multiple classes. We process the labels to be "multi-hot":
a vector of length $n$ where $n$ is the number of classes, where it is a 1 at position $i$ if 
it belongs to the $i^{th}$ class and 0 otherwise.
\subsection{Model}

The input of our model first goes through a batch normalization layer. This helps
us normalize the input to the pretrained model on our specific dataset, allowing us 
to feed the raw data in.

The ResNet50V2 model is conviniently structured into distinct residual blocks.
For our experiments we picked the outputs of 4 different residual blocks in the model
as our final feature map. The output of the chosen hidden layers is a large amount of 
feature maps, we chose not to directly flatten and connect it to a dense prediction
layer due to the amount of parameters that would need. We chose to reduce the number of 
feature maps from the output by first passing it through a 1x1 convolution layer with 
relu activation. This allows us to significantly reduce the number of feature maps and makes training faster. 
We then flatten the feature maps using global average pooling, and then connect to a 
fully connected dense layer for prediction. 

The dataset we are tackling is a multi label classification problem, therefore use sigmoid activation
in the prediction layer as each image can belong in multiple classes. We  use binary crossentropy as the loss function. 
\begin{equation}
    L(Y, \hat{Y}) = \sum_i^n y_i\log{(\hat{y}_i)}
\end{equation}
Where $Y$ is the "multi hot" representation of our label, $y_i$
is the value at each $i^{th}$ position in the label.  We assume that for every value in the output vector $\hat{y_i}$ is the probability
that an image is in class $i$, where each $\hat{y}_i$ is indenpendent of other class probabilities because 
each $x$ can belong to multiple classes at the same time. 

\subsection{Training}
To train the each model we used the ADAM optimization algorithm with minibatches of size 32.
The parameters we used for ADAM were: $\eta = 10^{-3}$, $\beta_1 = 0.9$, $beta_2=0.999$, these
are the default values in Keras' implementation of ADAM.
We were able to run 10 epochs of training on each model given our computing resources. 
\end{document}

