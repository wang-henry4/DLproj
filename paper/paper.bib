@incollection{NIPS2014_5347,
title = {How transferable are features in deep neural networks?},
author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
pages = {3320--3328},
year = {2014},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf}
}
@InProceedings{10.1007/978-3-319-10590-1_53,
author="Zeiler, Matthew D.
and Fergus, Rob",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Visualizing and Understanding Convolutional Networks",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="818--833",
abstract="Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",
isbn="978-3-319-10590-1"
}
@misc{szegedy2014going,
    title={Going Deeper with Convolutions},
    author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
    year={2014},
    eprint={1409.4842},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@article{Lin2013NetworkIN,
  title={Network In Network},
  author={Min Lin and Qiang Chen and Shuicheng Yan},
  journal={CoRR},
  year={2013},
  volume={abs/1312.4400}
}
@article{DBLP:journals/corr/HeZR016,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Identity Mappings in Deep Residual Networks},
  journal   = {CoRR},
  volume    = {abs/1603.05027},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.05027},
  archivePrefix = {arXiv},
  eprint    = {1603.05027},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZR016},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{imagenet_cvpr09,
    AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
    TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
    BOOKTITLE = {CVPR09},
    YEAR = {2009},
    BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"}
@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
